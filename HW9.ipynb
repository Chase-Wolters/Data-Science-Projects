{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a406609",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers datasets evaluate accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a73a978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4e4f173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['date', 'rating', 'title', 'text', 'property_dict', 'Name', 'City', 'County'],\n",
       "        num_rows: 21112546\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = \"guyhadad01/Hotels_reviews\"\n",
    "\n",
    "raw_datasets = load_dataset(dataset_name)\n",
    "raw_datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e0e416c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': '2019-01-01 00:00:00',\n",
       " 'rating': 5.0,\n",
       " 'title': 'Xmas holiday',\n",
       " 'text': 'We went here with our kids for Xmas holiday and we really liked it. Large options of food for breakfast and lunch , you can really taste the quality of the food in there. The surrounding area is nice and clean. Good experience. Hardly recommended .',\n",
       " 'property_dict': '{\"service\": null, \"location\": null, \"sleep quality\": null, \"rooms\": null, \"cleanliness\": null, \"value\": null, \"check in / front desk\": null, \"business service (e.g., internet access)\": null}',\n",
       " 'Name': 'Baltic',\n",
       " 'City': 'Giulianova Lido',\n",
       " 'County': 'Italy'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c807bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['date', 'rating', 'title', 'text', 'property_dict', 'Name', 'City', 'County', 'label'],\n",
       "    num_rows: 21112546\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def map_rating_to_label(example):\n",
    "    \"\"\"\n",
    "    Map 1-5 star rating to:\n",
    "    0 = Negative (1-2 stars)\n",
    "    1 = Neutral  (3 stars)\n",
    "    2 = Positive (4-5 stars)\n",
    "    \"\"\"\n",
    "    rating = example[\"rating\"]\n",
    "    # Some datasets store rating as float, some as int\n",
    "    # Convert to int just in case\n",
    "    r = int(round(rating))\n",
    "\n",
    "    if r <= 2:\n",
    "        label = 0\n",
    "    elif r == 3:\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 2\n",
    "\n",
    "    return {\"label\": label}\n",
    "\n",
    "labeled_dataset = raw_datasets[\"train\"].map(map_rating_to_label)\n",
    "labeled_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36a66ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle and select a subset for experimentation\n",
    "subset_size = 100_000  # adjust smaller/bigger based on your GPU/CPU\n",
    "\n",
    "labeled_dataset = labeled_dataset.shuffle(seed=42).select(range(subset_size))\n",
    "len(labeled_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "593253bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negative (0)    10569\n",
       "Neutral (1)     11598\n",
       "Positive (2)    77833\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts = pd.Series(labeled_dataset[\"label\"]).value_counts().sort_index()\n",
    "label_counts.index = [\"Negative (0)\", \"Neutral (1)\", \"Positive (2)\"]\n",
    "label_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef79aa97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['date', 'rating', 'title', 'text', 'property_dict', 'Name', 'City', 'County', 'label'],\n",
       "    num_rows: 100000\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import ClassLabel\n",
    "\n",
    "# Define the label names (optional but nice for readability)\n",
    "label_names = [\"negative\", \"neutral\", \"positive\"]\n",
    "\n",
    "# Copy existing features and replace \"label\" with a ClassLabel feature\n",
    "features = labeled_dataset.features.copy()\n",
    "features[\"label\"] = ClassLabel(num_classes=3, names=label_names)\n",
    "\n",
    "# Cast the dataset\n",
    "labeled_dataset = labeled_dataset.cast(features)\n",
    "\n",
    "labeled_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92718b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 20000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can do a stratified split by \"label\"\n",
    "dataset_split = labeled_dataset.train_test_split(\n",
    "    test_size=0.2,\n",
    "    stratify_by_column=\"label\"\n",
    ")\n",
    "\n",
    "train_dataset = dataset_split[\"train\"]\n",
    "val_dataset   = dataset_split[\"test\"]\n",
    "\n",
    "len(train_dataset), len(val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5094829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cwolt\\OneDrive\\Desktop\\Data-Science-Projects\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\cwolt\\.cache\\huggingface\\hub\\models--distilbert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"distilbert-base-uncased\"\n",
    "num_labels = 3  # Negative, Neutral, Positive\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels\n",
    ")\n",
    "\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7d8baa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 80000/80000 [00:15<00:00, 5250.04 examples/s]\n",
      "Map: 100%|██████████| 20000/20000 [00:03<00:00, 5483.97 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'label': tensor(2),\n",
       " 'input_ids': tensor([  101,  1996,  3309,  2003, 14057,  2135,  2284,  1999,  1996,  2103,\n",
       "          2803,  1010,  2485,  2000,  2048,  1057,  1011, 17392,  3703,  1998,\n",
       "          1037,  3181,  3295,  1006, 26520,  4918,  1007,  2073,  1996,  4068,\n",
       "          2813,  4055,  2264,  1998,  2225,  4068,  1012,  2045,  2024,  2116,\n",
       "          2248,  7884,  1999,  1996,  2181,  1012,  2116,  9941,  2024,  2485,\n",
       "          2011,  1998,  4089,  7801,  2011,  3345,  1012,  2057,  2020, 15936,\n",
       "          2011,  1996, 22445,  2282,  1998,  2019,  4866,  6350,  3659,  1006,\n",
       "          2348,  2025,  2443,  1999,  2256,  2282, 23234,  1007,  1012,  1996,\n",
       "          2392,  4624,  3095,  2001,  2200, 14044,  1999, 14669,  2149,  2005,\n",
       "          4356,  1011,  3773,  7562,  2030,  2005,  6265,  1998,  4596,  1012,\n",
       "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = 256  # good default for reviews\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "    )\n",
    "\n",
    "encoded_train = train_dataset.map(preprocess_function, batched=True)\n",
    "encoded_val   = val_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Keep only columns needed for training\n",
    "cols_to_keep = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "\n",
    "encoded_train = encoded_train.remove_columns(\n",
    "    [c for c in encoded_train.column_names if c not in cols_to_keep]\n",
    ")\n",
    "encoded_val = encoded_val.remove_columns(\n",
    "    [c for c in encoded_val.column_names if c not in cols_to_keep]\n",
    ")\n",
    "\n",
    "encoded_train.set_format(type=\"torch\")\n",
    "encoded_val.set_format(type=\"torch\")\n",
    "\n",
    "encoded_train[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ca87760",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 4.20kB [00:00, 440kB/s]\n"
     ]
    }
   ],
   "source": [
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    result = accuracy_metric.compute(predictions=preds, references=labels)\n",
    "    return result  # {\"accuracy\": ...}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e81c9f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(learning_rate, batch_size, num_epochs, run_name):\n",
    "    # fresh model each time (so experiments are comparable)\n",
    "    exp_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=num_labels\n",
    "    )\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./results/{run_name}\",\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=num_epochs,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"accuracy\",\n",
    "        greater_is_better=True,\n",
    "        report_to=\"none\",  # don't send to wandb/tensorboard unless you want to\n",
    "        run_name=run_name,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=exp_model,\n",
    "        args=training_args,\n",
    "        train_dataset=encoded_train,\n",
    "        eval_dataset=encoded_val,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    eval_results = trainer.evaluate()\n",
    "    val_acc = eval_results[\"eval_accuracy\"]\n",
    "    print(f\"{run_name} -> validation accuracy: {val_acc:.4f}\")\n",
    "    return val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71f24de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m lr \u001b[38;5;129;01min\u001b[39;00m learning_rates:\n\u001b[32m      5\u001b[39m     run_name = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mlr_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_bs_16_ep_3\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     acc = \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     results_lr.append({\n\u001b[32m     13\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     14\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m\"\u001b[39m: lr,\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mval_accuracy\u001b[39m\u001b[33m\"\u001b[39m: acc,\n\u001b[32m     18\u001b[39m     })\n\u001b[32m     20\u001b[39m df_lr = pd.DataFrame(results_lr)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mrun_experiment\u001b[39m\u001b[34m(learning_rate, batch_size, num_epochs, run_name)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_experiment\u001b[39m(learning_rate, batch_size, num_epochs, run_name):\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# fresh model each time (so experiments are comparable)\u001b[39;00m\n\u001b[32m      3\u001b[39m     exp_model = AutoModelForSequenceClassification.from_pretrained(\n\u001b[32m      4\u001b[39m         model_name,\n\u001b[32m      5\u001b[39m         num_labels=num_labels\n\u001b[32m      6\u001b[39m     )\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     training_args = \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./results/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrun_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevaluation_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mepoch\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43msave_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mepoch\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogging_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mepoch\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43mload_best_model_at_end\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetric_for_best_model\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maccuracy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgreater_is_better\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreport_to\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnone\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# don't send to wandb/tensorboard unless you want to\u001b[39;49;00m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m     trainer = Trainer(\n\u001b[32m     25\u001b[39m         model=exp_model,\n\u001b[32m     26\u001b[39m         args=training_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m         compute_metrics=compute_metrics,\n\u001b[32m     31\u001b[39m     )\n\u001b[32m     33\u001b[39m     trainer.train()\n",
      "\u001b[31mTypeError\u001b[39m: TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'"
     ]
    }
   ],
   "source": [
    "learning_rates = [2e-5, 5e-5, 1e-4]\n",
    "results_lr = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    run_name = f\"lr_{lr}_bs_16_ep_3\"\n",
    "    acc = run_experiment(\n",
    "        learning_rate=lr,\n",
    "        batch_size=16,\n",
    "        num_epochs=3,\n",
    "        run_name=run_name,\n",
    "    )\n",
    "    results_lr.append({\n",
    "        \"type\": \"learning_rate\",\n",
    "        \"lr\": lr,\n",
    "        \"batch_size\": 16,\n",
    "        \"epochs\": 3,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "df_lr = pd.DataFrame(results_lr)\n",
    "df_lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce1eef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [8, 16, 32]\n",
    "results_bs = []\n",
    "\n",
    "for bs in batch_sizes:\n",
    "    run_name = f\"lr_5e-5_bs_{bs}_ep_3\"\n",
    "    acc = run_experiment(\n",
    "        learning_rate=5e-5,\n",
    "        batch_size=bs,\n",
    "        num_epochs=3,\n",
    "        run_name=run_name,\n",
    "    )\n",
    "    results_bs.append({\n",
    "        \"type\": \"batch_size\",\n",
    "        \"lr\": 5e-5,\n",
    "        \"batch_size\": bs,\n",
    "        \"epochs\": 3,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "df_bs = pd.DataFrame(results_bs)\n",
    "df_bs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dadf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_values = [2, 3, 4]\n",
    "results_ep = []\n",
    "\n",
    "for ep in epoch_values:\n",
    "    run_name = f\"lr_5e-5_bs_16_ep_{ep}\"\n",
    "    acc = run_experiment(\n",
    "        learning_rate=5e-5,\n",
    "        batch_size=16,\n",
    "        num_epochs=ep,\n",
    "        run_name=run_name,\n",
    "    )\n",
    "    results_ep.append({\n",
    "        \"type\": \"epochs\",\n",
    "        \"lr\": 5e-5,\n",
    "        \"batch_size\": 16,\n",
    "        \"epochs\": ep,\n",
    "        \"val_accuracy\": acc,\n",
    "    })\n",
    "\n",
    "df_ep = pd.DataFrame(results_ep)\n",
    "df_ep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe074bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = pd.concat([df_lr, df_bs, df_ep], ignore_index=True)\n",
    "all_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392f0e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results.sort_values(\"val_accuracy\", ascending=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
